{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1424b78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.37.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\83688\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.6.15)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2af2b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category for Text 1: Terrorism / Protest / Political Unrest / Riot\n",
      "Predicted Category for Text 2: Natural Disasters\n",
      "Predicted Category for Text 3: Others modified\n",
      "Predicted Category for Text 4: Natural Disasters\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import feedparser\n",
    "from sqlalchemy import Column, Integer, String, DateTime\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from celery import Celery\n",
    "\n",
    "# Defining SQLAlchemy Base\n",
    "Base = declarative_base()\n",
    "\n",
    "# Defining Article ORM model\n",
    "class Article(Base):\n",
    "    __tablename__ = 'articles'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    title = Column(String)\n",
    "    content = Column(String)\n",
    "    publication_date = Column(DateTime)\n",
    "    source_url = Column(String, unique=True)\n",
    "    category = Column(String)\n",
    "\n",
    "# Initializing Celery\n",
    "celery = Celery('news_processor', broker='redis://localhost:6379/0')\n",
    "\n",
    "# Configuring logging\n",
    "logging.basicConfig(filename='news_processing.log', level=logging.INFO)\n",
    "\n",
    "# Function to parse RSS feeds\n",
    "@celery.task\n",
    "def parse_rss(feed_urls):\n",
    "    articles = []\n",
    "    for url in feed_urls:\n",
    "        feed = feedparser.parse(url)\n",
    "        \n",
    "        for entry in feed.entries:\n",
    "            \n",
    "#           \n",
    "            summary = entry.get('summary', '')\n",
    "            category = entry.get('category', '')\n",
    "\n",
    "            \n",
    "            publication_date_str = entry.get('published', '')\n",
    "            try:\n",
    "                publication_date = datetime.strptime(publication_date_str, '%a, %d %b %Y %H:%M:%S %Z')\n",
    "            except ValueError:\n",
    "                publication_date = None\n",
    "            article = {\n",
    "                'title': entry.get('title', ''),\n",
    "                'content': summary,\n",
    "                'publication_date': publication_date,\n",
    "                'source_url': entry.get('link', ''),\n",
    "                'category': ''\n",
    "            }\n",
    "            articles.append(article)\n",
    "            \n",
    "#     for article in articles:\n",
    "#         if article['category'] != 'others':\n",
    "#             print(article)\n",
    "            \n",
    "    return articles\n",
    "\n",
    "# Function to store articles in the database\n",
    "@celery.task\n",
    "def store_articles(articles):\n",
    "    print(\"hai from \", \"store_articles\")\n",
    "    engine = create_engine('sqlite:///news_db.sqlite')\n",
    "    Base.metadata.create_all(engine)\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "    for article_data in articles:\n",
    "        try:\n",
    "            article = Article(\n",
    "                title=article_data['title'],\n",
    "                content=article_data['content'],\n",
    "                publication_date=article_data['publication_date'],\n",
    "                source_url=article_data['source_url'],\n",
    "                category=article_data['category']\n",
    "            )\n",
    "            session.add(article)\n",
    "            session.commit()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error storing article: {str(e)}\")\n",
    "            session.rollback()\n",
    "\n",
    "    logging.info(\"store_articles function executed successfully\")  \n",
    "\n",
    "\n",
    "# Function to classify articles\n",
    "def classify_article(content):\n",
    "    # For demonstration, let's assume a simple rule-based classification\n",
    "    if \"terrorism\" in content.lower() or \"protest\" in content.lower() or \"political unrest\" in content.lower() or \"riot\" in content.lower():\n",
    "        return \"Terrorism / Protest / Political Unrest / Riot\"\n",
    "    elif \"positive\" in content.lower() or \"uplifting\" in content.lower():\n",
    "        return \"Positive/Uplifting\"\n",
    "    elif \"natural disaster\" in content.lower():\n",
    "        return \"Natural Disasters\"\n",
    "    else:\n",
    "        return \"Others modified\"\n",
    "\n",
    "# from transformers import TFAutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "# # Load the tokenizer and model using TensorFlow weights\n",
    "# tokenizer = TFAutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-imdb\")\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-imdb\")\n",
    "\n",
    "# def classify_article(content):\n",
    "#     if not content:\n",
    "#         return \"Others\"  # If the content is empty, classify as \"Others\"\n",
    "\n",
    "#     try:\n",
    "#         # Tokenize the content\n",
    "#         inputs = tokenizer(content, return_tensors=\"tf\", padding=True, truncation=True)\n",
    "\n",
    "#         # Forward pass through the model\n",
    "#         outputs = model(inputs)\n",
    "\n",
    "#         # Get the predicted label\n",
    "#         predicted_label_id = tf.argmax(outputs.logits, axis=1).numpy()[0]\n",
    "#         predicted_label = model.config.id2label[predicted_label_id]\n",
    "        \n",
    "#         print(\"Predicted label:\", predicted_label)\n",
    "#         return predicted_label\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error during classification: {str(e)}\")\n",
    "#         return \"Others\"\n",
    "\n",
    "\n",
    "# Function to categorize articles\n",
    "@celery.task\n",
    "def categorize_articles():\n",
    "    print(\"hai from categorize_articles\")\n",
    "    engine = create_engine('sqlite:///news_db.sqlite')\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "    \n",
    "    uncategorized_articles = session.query(Article).all()\n",
    "\n",
    "    # Fetch uncategorized articles\n",
    "#     uncategorized_articles = session.query(Article).filter(Article.category == '').all()\n",
    "    \n",
    "#     print(\"uncategorized_articles knri\", uncategorized_articles)\n",
    "#     return\n",
    "\n",
    "    # Assuming you have a trained text classification model (model)\n",
    "    for article in uncategorized_articles:\n",
    "#         print(\"article is \", article.content)\n",
    "        # Perform text classification on article content to determine its category\n",
    "        category = classify_article(article.content)\n",
    "\n",
    "        # Update the category in the database\n",
    "        article.category = category\n",
    "        session.add(article)\n",
    "\n",
    "    # Commit changes to the database\n",
    "    session.commit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run tasks\n",
    "    feed_urls = [\n",
    "        'http://rss.cnn.com/rss/cnn_topstories.rss',\n",
    "        'http://qz.com/feed',\n",
    "        'http://feeds.foxnews.com/foxnews/politics',\n",
    "        'http://feeds.reuters.com/reuters/businessNews',\n",
    "        'http://feeds.feedburner.com/NewshourWorld',\n",
    "        'https://feeds.bbci.co.uk/news/world/asia/india/rss.xml'\n",
    "    ]\n",
    "#     extracted_articles = parse_rss(feed_urls)\n",
    "#     print(\"extracted_articles\", extracted_articles)\n",
    "#     store_articles(extracted_articles)\n",
    "\n",
    "\n",
    "#     my_text = \"The quick brown fox jumps over the riot dog\"\n",
    "#     result = classify_article(my_text)\n",
    "#     print(\"result is \", result)\n",
    "    categorize_articles()\n",
    "\n",
    "#    # Sample text data for testing\n",
    "#     sample_text_1 = \"This article discusses the recent protests in the city.\"\n",
    "#     sample_text_2 = \"A heartwarming story about a community coming together after a natural disaster.\"\n",
    "#     sample_text_3 = \"The stock market saw a significant rise today, bringing positivity to investors.\"\n",
    "#     sample_text_4 = \"A report on the impact of climate change and the increasing frequency of natural disasters.\"\n",
    "\n",
    "#     # Call the classification function for each sample text\n",
    "#     category_1 = classify_article(sample_text_1)\n",
    "#     category_2 = classify_article(sample_text_2)\n",
    "#     category_3 = classify_article(sample_text_3)\n",
    "#     category_4 = classify_article(sample_text_4)\n",
    "\n",
    "#     # Print the predicted categories\n",
    "#     print(\"Predicted Category for Text 1:\", category_1)\n",
    "#     print(\"Predicted Category for Text 2:\", category_2)\n",
    "#     print(\"Predicted Category for Text 3:\", category_3)\n",
    "#     print(\"Predicted Category for Text 4:\", category_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bdd0108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id                                              title  \\\n",
      "0   161  India calls Pakistan's claim of targeted killi...   \n",
      "1   162  Tamil Nadu: Chennaiâ€™s 'last Jew' fights for pl...   \n",
      "2   163  India v England: 'Hyderabad Heist shows Englan...   \n",
      "3   164              Rohan Bopanna: 'Age is just a number'   \n",
      "4   165  Adani Ports: The Tamil Nadu villagers taking o...   \n",
      "5   166  Umar Khalid: Indian activist languishes in jai...   \n",
      "6   167         Women take the lead in Republic Day parade   \n",
      "7   168  Watch: Crowds at India's new Ram temple in Ayo...   \n",
      "8   169       Indian PM Modi inaugurates temple in Ayodhya   \n",
      "9   170            Plane gets jammed under bridge in India   \n",
      "10  171       Intruder jumps on table in Indian parliament   \n",
      "11  172      Moment worker is pulled from collapsed tunnel   \n",
      "12  173     First video of trapped tunnel workers in India   \n",
      "\n",
      "                                              content  \\\n",
      "0   Islamabad on Thursday accused India of killing...   \n",
      "1   Davvid Levi has been documenting the history o...   \n",
      "2   The astonishing victory over India in Hyderaba...   \n",
      "3   India's Rohan Bopanna, 43, becomes the oldest ...   \n",
      "4   Locals in 100 villages of Tamil Nadu state are...   \n",
      "5   Umar Khalid, who was arrested three years ago ...   \n",
      "6   Every year, the country celebrates the day its...   \n",
      "7   The grand temple dedicated to the Hindu God Ra...   \n",
      "8   The opening of the grand temple comes ahead of...   \n",
      "9   The scrap fuselage was on its way to Assam fro...   \n",
      "10  Lawmakers said two men jumped into the well of...   \n",
      "11  Fourty-one Indian workers are finally rescued ...   \n",
      "12  Rescuers have shared a video of the 41 workers...   \n",
      "\n",
      "              publication_date  \\\n",
      "0   2024-01-26 07:04:26.000000   \n",
      "1   2024-01-27 03:25:03.000000   \n",
      "2   2024-01-28 19:18:36.000000   \n",
      "3   2024-01-27 15:42:34.000000   \n",
      "4   2024-01-24 02:39:32.000000   \n",
      "5   2024-01-23 00:32:22.000000   \n",
      "6   2024-01-26 09:05:05.000000   \n",
      "7   2024-01-23 09:47:15.000000   \n",
      "8   2024-01-22 08:06:54.000000   \n",
      "9   2023-12-29 23:17:00.000000   \n",
      "10  2023-12-13 09:49:30.000000   \n",
      "11  2023-11-28 15:13:21.000000   \n",
      "12  2023-11-21 05:58:33.000000   \n",
      "\n",
      "                                           source_url category  \n",
      "0   https://www.bbc.co.uk/news/world-asia-india-68...   Others  \n",
      "1   https://www.bbc.co.uk/news/world-asia-india-67...   Others  \n",
      "2   https://www.bbc.co.uk/sport/cricket/68123032?a...   Others  \n",
      "3   https://www.bbc.co.uk/sport/tennis/68117965?at...   Others  \n",
      "4   https://www.bbc.co.uk/news/world-asia-india-67...   Others  \n",
      "5   https://www.bbc.co.uk/news/world-asia-india-67...   Others  \n",
      "6   https://www.bbc.co.uk/news/world-asia-india-68...   Others  \n",
      "7   https://www.bbc.co.uk/news/world-asia-india-68...   Others  \n",
      "8   https://www.bbc.co.uk/news/world-asia-india-68...   Others  \n",
      "9   https://www.bbc.co.uk/news/world-asia-india-67...   Others  \n",
      "10  https://www.bbc.co.uk/news/world-asia-india-67...   Others  \n",
      "11  https://www.bbc.co.uk/news/world-asia-india-67...   Others  \n",
      "12  https://www.bbc.co.uk/news/world-asia-india-67...   Others  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Connect to the SQLite database\n",
    "engine = create_engine('sqlite:///news_db.sqlite')\n",
    "\n",
    "# Query all articles from the database\n",
    "query = \"SELECT * FROM articles\"\n",
    "articles_df = pd.read_sql(query, engine)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(articles_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2b099d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame to a CSV file\n",
    "articles_df.to_csv('articles.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5942b65a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
